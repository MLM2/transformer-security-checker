# ğŸ›¡ï¸ Transformer Security Checker

This project evaluates the robustness of transformer-based NLP models (e.g., BERT) against adversarial attacks using the [TextAttack](https://github.com/QData/TextAttack) framework.

## ğŸ¯ Goal
Raise awareness of security vulnerabilities in NLP systems by demonstrating how minor text perturbations can lead to model misclassification. Relevant for AI risk assessments, robust ML development, and national security contexts.

---

## ğŸ—‚ï¸ Project Structure

# ğŸ›¡ï¸ Transformer Security Checker

This project evaluates the robustness of transformer-based NLP models (e.g., BERT) against adversarial attacks using the [TextAttack](https://github.com/QData/TextAttack) framework.

## ğŸ¯ Goal
Raise awareness of security vulnerabilities in NLP systems by demonstrating how minor text perturbations can lead to model misclassification. Relevant for AI risk assessments, robust ML development, and national security contexts.

---

## ğŸ—‚ï¸ Project Structure


